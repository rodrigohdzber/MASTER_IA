{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 7 historico indices Yahoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Obtén los datos históricos de cada índice (60 días)\n",
    "- Recomendación: Yahoo Finance. Tiempo objetivo: 45 minutos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rcurl\n",
      "  Downloading https://files.pythonhosted.org/packages/7e/c7/f9f070a787c8af6eb7d35e5ba56c0cc60ed6c219fc4bc6237e292e2c8faf/rcurl-0.0.2-py3-none-any.whl\n",
      "Installing collected packages: rcurl\n",
      "Successfully installed rcurl-0.0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 18.1, however version 20.2b1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install rcurl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup #https://www.freecodecamp.org/news/how-to-scrape-websites-with-python-and-beautifulsoup-5946935d93fe#/\n",
    "import datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from rcurl import get_curl #https://pypi.org/project/rcurl/\n",
    "from io import BytesIO\n",
    "from time import mktime\n",
    "from datetime import timedelta\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recupero los datos en bruto de Yahoo finance, realizando el chequeo del crumb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_crumbs_and_cookies(stock):\n",
    "    \"\"\"\n",
    "    get crumb and cookies for historical data csv download from yahoo finance\n",
    "    parameters: stock - short-handle identifier of the company \n",
    "    returns a tuple of header, crumb and cookie\n",
    "    \"\"\"\n",
    "    \n",
    "    url = 'https://finance.yahoo.com/quote/{}/history'.format(stock)\n",
    "    \n",
    "    with requests.session():\n",
    "        \n",
    "        header = {'Connection': 'keep-alive',\n",
    "                   'Expires': '-1',\n",
    "                   'Upgrade-Insecure-Requests': '1',\n",
    "                   'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) \\\n",
    "                   AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36'\n",
    "                   }\n",
    "        \n",
    "        website = requests.get(url, headers=header)\n",
    "        soup = BeautifulSoup(website.text, 'lxml')\n",
    "        crumb = re.findall('\"CrumbStore\":{\"crumb\":\"(.+?)\"}', str(soup))\n",
    "\n",
    "        return (header, crumb[0], website.cookies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos el rango de fechas que queremos importar.\n",
    "\n",
    "Yahoo utiliza formato de fecha poxis - time unix\n",
    "(cantidad de segundos transcurridos desde la medianoche UTC del 1 de enero de 1970, teniendo cada día 86400 segundos)\n",
    "\n",
    "Convertimos la fecha a formato poxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_unix(date):\n",
    "    \"\"\"\n",
    "    converts date to unix timestamp    \n",
    "    parameters: date - in format (yyyy-mm-dd)    \n",
    "    returns integer unix timestamp\n",
    "    \"\"\"\n",
    "    datum = datetime.strptime(date, '%Y-%m-%d')\n",
    "    \n",
    "    return int(mktime(datum.timetuple()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(stock, interval='1d', day_begin='20-03-2018', day_end='20-06-2018'):\n",
    "    \"\"\"\n",
    "    queries yahoo finance api to receive historical data in csv file format\n",
    "    \n",
    "    parameters: \n",
    "        stock - short-handle identifier of the company\n",
    "        \n",
    "        interval - 1d, 1wk, 1mo - daily, weekly monthly data\n",
    "        \n",
    "        day_begin - starting date for the historical data (format: dd-mm-yyyy)\n",
    "        \n",
    "        day_end - final date of the data (format: dd-mm-yyyy)\n",
    "    \n",
    "    returns a list of comma seperated value lines\n",
    "    \"\"\"\n",
    "    day_begin_unix = convert_to_unix(day_begin)\n",
    "    day_end_unix = convert_to_unix(day_end)       \n",
    "    header, crumb, cookies = _get_crumbs_and_cookies(stock)\n",
    "    \n",
    "    with requests.session():\n",
    "        url = 'https://query1.finance.yahoo.com/v7/finance/download/'               '{stock}?period1={day_begin}&period2={day_end}&interval={interval}&events=history&crumb={crumb}'               .format(stock=stock, day_begin=day_begin_unix, day_end=day_end_unix, interval=interval, crumb=crumb)\n",
    "                \n",
    "        website = requests.get(url, headers=header, cookies=cookies)\n",
    "       \n",
    "        return website.text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_de_indices=(\"%5EBFX\",\"%5EBVSP\", \"%5EDJI\", \"%5EFCHI\", \"%5EFTSE\", \"%5EGDAXI\", \"%5EHSI\", \"%5EIBEX\", \n",
    "                    \"%5EMXX\", \"%5EJKSE\", \"%5EMERV\", \"%5EOMXSPI\", \"%5EOSEAX\", \"%5ESSMI\", \"%5ESTI\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos las fechas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-30\n",
      "2020-05-01\n"
     ]
    }
   ],
   "source": [
    "ventana=60\n",
    "\n",
    "hoy = datetime.now()\n",
    "fecha_fin = str(hoy.now())\n",
    "fecha_fin = fecha_fin[0:10]\n",
    "print(fecha_fin)\n",
    "\n",
    "fecha_inicial = hoy-timedelta(ventana)\n",
    "fecha_inicial = str(fecha_inicial)\n",
    "fecha_inicial = fecha_inicial[0:10]\n",
    "print(fecha_inicial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descargamos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descargando %5EBFX\n",
      "descargando %5EBVSP\n",
      "descargando %5EDJI\n",
      "descargando %5EFCHI\n",
      "descargando %5EFTSE\n",
      "descargando %5EGDAXI\n",
      "descargando %5EHSI\n",
      "descargando %5EIBEX\n",
      "descargando %5EMXX\n",
      "descargando %5EJKSE\n",
      "descargando %5EMERV\n",
      "descargando %5EOMXSPI\n",
      "descargando %5EOSEAX\n",
      "descargando %5ESSMI\n",
      "descargando %5ESTI\n"
     ]
    }
   ],
   "source": [
    "for benchmark in tickers_de_indices:\n",
    "    \n",
    "    print(\"descargando \"+benchmark)\n",
    "    \n",
    "    try:\n",
    "        DF=load_csv_data(benchmark, interval='1d', day_begin=fecha_inicial, day_end=fecha_fin)\n",
    "    except:\n",
    "        print(\"No nos hemos podido descargar el indice\")\n",
    "    \n",
    "    DF=pd.DataFrame(DF)\n",
    "    DF = DF.iloc[:,0].str.split(\",\", n = 7, expand = True)\n",
    "    DF.columns=DF.iloc[0,:]\n",
    "    DF=DF.iloc[1:DF.shape[0],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-05-04</td>\n",
       "      <td>2555.669922</td>\n",
       "      <td>2575.139893</td>\n",
       "      <td>2536.629883</td>\n",
       "      <td>2563.689941</td>\n",
       "      <td>2563.689941</td>\n",
       "      <td>349485700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-05-05</td>\n",
       "      <td>2579.100098</td>\n",
       "      <td>2595.129883</td>\n",
       "      <td>2572.360107</td>\n",
       "      <td>2572.360107</td>\n",
       "      <td>2572.360107</td>\n",
       "      <td>220314200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-05-06</td>\n",
       "      <td>2566.689941</td>\n",
       "      <td>2608.010010</td>\n",
       "      <td>2565.939941</td>\n",
       "      <td>2591.600098</td>\n",
       "      <td>2591.600098</td>\n",
       "      <td>294626700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>2600.379883</td>\n",
       "      <td>2602.429932</td>\n",
       "      <td>2579.360107</td>\n",
       "      <td>2591.879883</td>\n",
       "      <td>2591.879883</td>\n",
       "      <td>330465700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-05-11</td>\n",
       "      <td>2597.850098</td>\n",
       "      <td>2611.739990</td>\n",
       "      <td>2590.659912</td>\n",
       "      <td>2611.310059</td>\n",
       "      <td>2611.310059</td>\n",
       "      <td>260504400</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "0        Date         Open         High          Low        Close  \\\n",
       "1  2020-05-04  2555.669922  2575.139893  2536.629883  2563.689941   \n",
       "2  2020-05-05  2579.100098  2595.129883  2572.360107  2572.360107   \n",
       "3  2020-05-06  2566.689941  2608.010010  2565.939941  2591.600098   \n",
       "4  2020-05-08  2600.379883  2602.429932  2579.360107  2591.879883   \n",
       "5  2020-05-11  2597.850098  2611.739990  2590.659912  2611.310059   \n",
       "\n",
       "0    Adj Close     Volume  \n",
       "1  2563.689941  349485700  \n",
       "2  2572.360107  220314200  \n",
       "3  2591.600098  294626700  \n",
       "4  2591.879883  330465700  \n",
       "5  2611.310059  260504400  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otra manera de hacerlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import requests\n",
    "from io import StringIO\n",
    "from datetime import datetime,timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_de_indices=[\"%5EBFX\",\"%5EBVSP\", \"%5EDJI\", \"%5EFCHI\", \"%5EFTSE\", \"%5EGDAXI\", \"%5EHSI\", \"%5EIBEX\", \"%5EMXX\", \"%5EJKSE\", \"%5EMERV\", \"%5EOMXSPI\", \"%5EOSEAX\", \"%5ESSMI\", \"%5ESTI\"]\n",
    "ventana=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datos_indices (tickers_de_indices,ventana):\n",
    "    for benchmark in tickers_de_indices:\n",
    "        print(benchmark+\" descargando\")\n",
    "        \n",
    "        # Obtengo las cookies de su web \n",
    "        cookieProcessor = urllib.request.HTTPCookieProcessor()\n",
    "        opener = urllib.request.build_opener(cookieProcessor)\n",
    "        \n",
    "        # Una vez obtenida la cookie hago el res la url y obtengo todo el html para calcular crumb\n",
    "        res=str(opener.open(\"https://es.finance.yahoo.com/quote/\"+benchmark+\"?ltr=1\").read())\n",
    "        \n",
    "        # Buscamos y filtramos CrumbStore obteniendo el \"pass\" del crumb\n",
    "        posicion=res.find('CrumbStore')\n",
    "        crumb=res[posicion:posicion+35].split()\n",
    "        inicio=crumb[0].find(':\"')\n",
    "        final=crumb[0].find('\"}')\n",
    "        crumb=crumb[0][inicio+2:final]\n",
    "        \n",
    "        # Convertimos las fechas al formato correspondiente y calculamos con la ventana el rango a obteer\n",
    "        fecha_fin=int(round(time.time()))\n",
    "        fecha_inicio=datetime.now()-timedelta(ventana)\n",
    "        fecha_inicio=int(round(fecha_inicio.timestamp()))\n",
    "        \n",
    "        # Construimos la url con todo lo calculado anteriormente y guardamos los .csv en DF\n",
    "        url=\"https://query1.finance.yahoo.com/v7/finance/download/\"+benchmark+\"?period1=\"+str(fecha_inicio)+\"&period2=\"+str(fecha_fin)+\"&interval=1d&events=history&crumb=\"+str(crumb)\n",
    "        req = requests.get(url)\n",
    "        data = StringIO(req.text)\n",
    "        indices=pd.read_csv(data)\n",
    "        \n",
    "        #Guardamos los nombres de los df con el nombre del inice sin el %5 pasado en tickers_de_indices \n",
    "        globals()[benchmark.replace(\"%5\", \"\").replace(\".\",\"_\")]=indices\n",
    "        print(\"Guardamos datos: \" +benchmark+ \" con nombre: \" +benchmark.replace(\"%5\", \"\").replace(\".\",\"_\"))\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_indices(tickers_de_indices,ventana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EJKSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otra manera de hacerlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import io\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_de_indices = [\n",
    "    \"%5EBFX\", \"%5EBVSP\", \"%5EDJI\", \"%5EFCHI\", \"%5EFTSE\",\n",
    "    \"%5EGDAXI\", \"%5EHSI\", \"%5EIBEX\", \"%5EMXX\", \"%5EJKSE\",\n",
    "    \"%5EMERV\", \"%5EOMXSPI\", \"%5EOSEAX\", \"%5ESSMI\", \"%5ESTI\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtener_indice(url, cookies):\n",
    "    try:\n",
    "        benchmark = requests.get(url, cookies=cookies).text\n",
    "        benchmark = io.StringIO(benchmark)\n",
    "        \n",
    "    except Exception as e:\n",
    "        \n",
    "        print(\"No nos hemos podido descargar el indice\")\n",
    "        print(\"Este es el mensaje de error que ha dado:\")\n",
    "        print(e)\n",
    "\n",
    "        return(\"Sin datos\")\n",
    "\n",
    "    return benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventana = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for benchmark in tickers_de_indices:\n",
    "\n",
    "    print(f'{benchmark} descargando')\n",
    "\n",
    "    # html de la web del benchmark\n",
    "    request = requests.get(f\"https://es.finance.yahoo.com/quote/{benchmark}?ltr=1\")\n",
    "    res = request.text\n",
    "\n",
    "    # Obtenemos el CrumbStore\n",
    "    pattern_crumbstore = r'\\\"CrumbStore\\\"\\:{\\\"crumb\\\":\\\"(?P<crumb>.*?)\\\"}'\n",
    "    crumb = re.search(pattern_crumbstore, res).groupdict().get('crumb')\n",
    "    crumb = crumb.replace(\"\\n\", \"\")  # Algunas veces, el crumb tiene una función de escape (un salto de página).\n",
    "\n",
    "    # Fechas inicio y fin\n",
    "    fecha_inicial = (datetime.now() - relativedelta(days=ventana)).strftime('%s')\n",
    "    fecha_fin = datetime.now().strftime('%s')\n",
    "\n",
    "    # Construimos la url para bajarnos los datos\n",
    "    url = f\"https://query1.finance.yahoo.com/v7/finance/download/{benchmark}?period1={fecha_inicial}&period2={fecha_fin}&interval=1d&events=history&crumb={crumb}\"\n",
    "\n",
    "    # Obtenemos indice a partir de la url\n",
    "    benchmark_io = obtener_indice(url, request.cookies)\n",
    "    data = pd.read_csv(benchmark_io)\n",
    "\n",
    "    globals()[benchmark] = data\n",
    "\n",
    "    print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otra manera de hacerlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from rcurl import get_curl\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ventana = 60\n",
    "fecha_fin=int(time.time())\n",
    "fecha_inicio=int(fecha_fin-86400*ventana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [\"%5EBFX\",\"%5EBVSP\", \"%5EDJI\", \"%5EFCHI\", \"%5EFTSE\", \"%5EGDAXI\", \"%5EHSI\", \"%5EIBEX\", \"%5EMXX\", \"%5EJKSE\", \"%5EMERV\", \"%5EOMXSPI\", \"%5EOSEAX\", \"%5ESSMI\", \"%5ESTI\"]\n",
    "\n",
    "for benchmark in indices:\n",
    "    url = f\"https://es.finance.yahoo.com/quote/{benchmark}?ltr=1\"\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html')\n",
    "    linea=str(soup)\n",
    "    linea=linea[linea.find('CrumbStore'):(linea.find('CrumbStore')+50)]\n",
    "    crumb=linea[(linea.find(':\"')+2):linea.find('\"}')]\n",
    "    new_url=f'https://query1.finance.yahoo.com/v7/finance/download/{benchmark}?period1={fecha_inicio}&period2={fecha_fin}&interval=1d&events=history&crumb={crumb}'\n",
    "    contenido=requests.get(new_url)\n",
    "    tabla = pd.read_csv(new_url, encoding='utf-8')\n",
    "    print(f'Descargando datos del indice {benchmark}')\n",
    "    print(tabla)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otra manera de hacerlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from time import mktime\n",
    "import requests    \n",
    "from bs4 import BeautifulSoup\n",
    "import re   \n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [\"%5EBFX\",\"%5EBVSP\", \"%5EDJI\",\n",
    "           \"%5EFCHI\", \"%5EFTSE\", \"%5EGDAXI\",\n",
    "           \"%5EHSI\", \"%5EIBEX\", \"%5EMXX\",\n",
    "           \"%5EJKSE\", \"%5EMERV\", \"%5EOMXSPI\",\n",
    "           \"%5EOSEAX\", \"%5ESSMI\", \"%5ESTI\"]\n",
    "\n",
    "ventana = 60\n",
    "end_date = datetime.today()\n",
    "start_date = end_date.today() - timedelta(days=ventana)\n",
    "\n",
    "end_date_unix = int(mktime(end_date.date().timetuple()))\n",
    "start_date_unix = int(mktime(start_date.date().timetuple()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index(index:str, start_date_unix:int,  end_date_unix:int):\n",
    "    \n",
    "    result = None\n",
    "    try:\n",
    "        url = f\"https://es.finance.yahoo.com/quote/{index}?ltr=1\"\n",
    "        website = requests.get(url) \n",
    "        soup = BeautifulSoup(website.text)\n",
    "        crumb = re.findall('\"CrumbStore\":{\"crumb\":\"(.+?)\"}', str(soup))[0]\n",
    "        url2 = f\"https://query1.finance.yahoo.com/v7/finance/download/{index}?period1={start_date_unix}&period2={end_date_unix}&interval=1d&events=history&crumb={crumb}\"\n",
    "        website = requests.get(url2).text.split('\\n')\n",
    "        table = [line.split(',') for line in website]\n",
    "        result = pd.DataFrame(data=table[1:], columns=table[0])\n",
    "        result.set_index('Date', inplace=True)\n",
    "        result['Open'] = result['Open'].astype(float)\n",
    "        result['High'] = result['High'].astype(float)\n",
    "        result['Low'] = result['Low'].astype(float)\n",
    "        result['Close'] = result['Close'].astype(float)\n",
    "        result['Adj Close'] = result['Adj Close'].astype(float)\n",
    "        result['Volume'] = result['Volume'].astype(float)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f'Index {index} could not be downloaded.')\n",
    "        print(e)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {index:get_index(index, start_date_unix, end_date_unix) for index in tqdm(indices)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result[indices[0]].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit ('venv-ml': venv)",
   "language": "python",
   "name": "python36864bitvenvmlvenve40bc169c9714114b4130d652b923ecf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
