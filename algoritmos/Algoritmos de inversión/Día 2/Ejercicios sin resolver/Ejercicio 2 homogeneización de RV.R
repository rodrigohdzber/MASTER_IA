# Al descargarnos los activos, podemos ver cómo todos ellos tienen el mismo número de variables (columnas), pero cotizaciones distintas (filas). 
# El siguiente objetivo es conseguir homogeneizar todos los datos. Las cotizaciones de cada activo deben de estar en las mismas líneas para poder realizar cálculos. 
# Objetivo: Homogeneiza los datos del benchmark y los activos con una ventana de 500 días.
# Tiempo objetivo: 45 minutos


library(RCurl)
library(stringr)
library(stringi)
library(rvest)
library(zoo) 

tickers_de_indices<-c("%5EBFX","%5EBVSP", "%5EDJI", "%5EFCHI", "%5EFTSE", "%5EGDAXI", "%5EHSI", "%5EIBEX", 
                      "%5EMXX", "%5EJKSE", "%5EMERV", "%5EOMXSPI", "%5EOSEAX", "%5ESSMI", "%5ESTI")

ventana <- XXXXXXXXXXXXXXX

# Extraemos la función homogeneizar datos
homogeneizar<-function(datos, ventana){
  
  fechas<- XXXXXXXXXXXXXXXXX # Creamos un vector con todas las fechas entre el día inicial y el final.
  dias_laborables<- XXXXXXXXXXXXXXXXXX # No nos interesan los sábados y domingos. Los localizamos.
  fechas<-XXXXXXXXXXXXXXXX # Filtramos la serie de datos usando el índice booleano anterior.
  
  # Volcamos los datos en un DF homogeneizado, utilizando la columna de fechas como índice.
  datos_homogeneizados<- XXXXXXXXXXXXXXXX
  
  # Ordenamos los datos por fecha (al hacer el merge se ha invertido el orden)
  datos_homogeneizados<- XXXXXXXXXXXXXXXXXXX 
  
  return(datos_homogeneizados)
}


# Extraemos la función que intenta obtener los datos del índice.
obtener_indice<-function(url, curl){
  benchmark <- tryCatch(    
    {
      benchmark = getURLContent(url, curl = curl, verbose = F)  
    },
    
    error=function(cond) {
      message("No nos hemos podido descargar el indice")
      message("Este es el mensaje de error que ha dado:")
      message(cond)
      
      return("Sin datos")
    },
    
    finally={
    }
  )    
  return(benchmark)
}

# Función que intenta obtener los datos de cada activo
obtener_datos_activo<-function(activo, fecha_inicial, fecha_fin, columna_fechas){
  info_activo <- tryCatch(
    {
      # Obtengo las cookies de su web (curl) 
      curl = getCurlHandle(cookiejar="", verbose = F)
      res = getURI(paste("https://es.finance.yahoo.com/quote/",activo,"?ltr=1", sep=""), curl = curl) 
      
      # Buscamos CrumbStore dentro del código que nos hemos bajado.
      posicion<-unlist(str_locate_all(pattern ='CrumbStore', res))
      crumb<-unlist(strsplit(substr(res, posicion[1], posicion[2]+30), "\""))
      crumb<-crumb[nchar(crumb)==max(nchar(crumb))]
      crumb<-stri_escape_unicode(crumb) # Algunas veces, el crumb tiene una función de escape (un salto de página). Lo eliminamos
      
      # Construimos la url para bajarnos los datos
      url<-paste("https://query1.finance.yahoo.com/v7/finance/download/",activo,"?period1=",fecha_inicial,"&period2=",fecha_fin,"&interval=1d&events=history&crumb=",crumb, sep="")
      
      # En la llamada tenemos que pasar la url con el crumb y la cookie.
      info_activo = getURLContent(url, curl = curl, verbose = F)
      info_activo <- read.csv ( textConnection ( info_activo ) , header = T )
      
      # No es necesario que indique el valor de retorno a través de `return ()` en el código.
    },
    
    error=function(cond) {
      message(paste("No nos hemos podido descargar el activo :", activo))
      message("Este es el mensaje de error que ha dado:")
      message(cond)
      
      # Generamos un DF a ceros, con el tamaño adecuado, para que los siguientes pasos no den error.
      info_activo<-as.data.frame(matrix(0,nrow=length(columna_fechas),ncol=7,byrow=F)) 
      info_activo$V1<-columna_fechas
      colnames(info_activo)<-c("Date", "Open", "High", "Low", "Close", "Adj.Close", "Volume")
      
      return(info_activo)
    },
    
    warning=function(cond) {
      message(paste("Nos ha dado un warning con el siguiente activo :", activo))
      message("Este el el mensaje de warning que ha dado:")
      message(cond)
      
      # Generamos un DF a ceros, con el tamaño adecuado, para que los siguientes pasos no den error.
      info_activo<-as.data.frame(matrix(0,nrow=ventana,ncol=7,byrow=F)) 
      colnames(info_activo)<-c("Date", "Open", "High", "Low", "Close", "Adj.Close", "Volume")
      
      return(info_activo)
    },
    finally={
    }
  )    
  return(info_activo)
}


# Ejecutamos el algoritmo
for(indice in tickers_de_indices){
  
  print(indice)
  
  # Extraemos el índice del listado de índices
  benchmark<-indice
  
  # Establecemos el rango de fechas que queremos importar.
  tiempo<-as.character(Sys.time())
  substr(tiempo, 12, 24) <- "00:00:00"
  tiempo<-as.POSIXct(tiempo)
  fecha_fin <-ceiling(as.numeric(as.POSIXct(tiempo)))
  fecha_inicial <- ceiling(as.numeric(as.POSIXct(tiempo - ventana*86400)))
  
  # Obtengo las cookies de su web (curl) 
  curl = getCurlHandle(cookiejar="", verbose = F)
  res = getURI(paste("https://es.finance.yahoo.com/quote/",benchmark,"?ltr=1", sep=""), curl = curl) 
  
  # Buscamos CrumbStore dentro del código que nos hemos bajado.
  posicion<-unlist(str_locate_all(pattern ='CrumbStore', res))
  crumb<-unlist(strsplit(substr(res, posicion[1], posicion[2]+30), "\""))
  crumb<-crumb[nchar(crumb)==max(nchar(crumb))]
  crumb<-stri_escape_unicode(crumb) # Algunas veces, el crumb tiene una función de escape (un salto de página). Lo eliminamos.  
  
  # Construimos la url para bajarnos los datos
  url<-paste("https://query1.finance.yahoo.com/v7/finance/download/",benchmark,"?period1=",fecha_inicial,"&period2=",fecha_fin,"&interval=1d&events=history&crumb=",crumb, sep="")
  
  # En la llamada tenemos que pasar la url con el crumb y la cookie.
  intentos<-0
  benchmark<-"Sin datos"
  while(benchmark=="Sin datos"){
    
    benchmark<-obtener_indice(url, curl)
    
    intentos<-intentos+1
    if(intentos>3){
      benchmark=="No descargable"
      print(c("Tras varios intentos no nos hemos podido descargar el índice ",tickers_de_indices[6]))
      return()
    }
    
    if(benchmark=="Sin datos"){
      print("Error en la descarga del benckmark, reintentamos")
      Sys.sleep(30)
    }
  }
  
  benchmark <- read.csv ( textConnection ( benchmark ) , header = T )
  
  # Hay veces que el último día se descarga dos veces en el DF. La segunda vez, la columna de volumen está a cero. 
  if (benchmark$Date[length(benchmark$Date)]==benchmark$Date[length(benchmark$Date)-1]){
    benchmark<-benchmark[1:(dim(benchmark)[1]-1),]
  }
  
  # Cogemos la columna de fechas del índice para usarla cuando no nos consigamos bajar algún activo.
  columna_fechas<-benchmark$Date
  columna_fechas<-as.vector(t(columna_fechas))
  
  # Obtenemos los activos que contiene cada índice.
  intentos<-0
  descarga<-"Sin datos"
  while(descarga=="Sin datos"){
    
    tryCatch(    
      {
        # Construimos la url que contiene la información de los activos de cada índice.
        web<-read_html(paste("https://es.finance.yahoo.com/quote/",indice,"/components/", sep=""))
        descarga<-"OK"
      },
      error=function(cond) {
        
        intentos<-intentos+1
        
        if(intentos>3){
          print("Tras varios intentos no nos hemos podido descargar los activos del índice. Dejamos de intentarlo.")
          return()
        }
        
        if(descarga=="Sin datos"){
          print("Error en la descarga de los activos del índice, reintentamos")
          Sys.sleep(30)
        }
        
      },
      finally={}
    ) 
  }
  
  datos_web<- web %>%
    html_nodes("td") %>% 
    html_text() 
  datos_web<-as.data.frame(datos_web) # Obtenemos cada celda de la tabla por separado. 
  datos_web<-as.data.frame(datos_web[1:(dim(datos_web)[1]-2),1]) # Eliminamos las últimas filas.
  
  if (dim(datos_web)[1]>1){ # Comprobamos si Yahoo publica algún activo del índice. Si la longitud es 1, no.
    
    # Reconstruimos la tabla. Tiene 6 columnas (simbolo, nombre de la empresa, último precio, cambio, cambio % y volumen.)
    # Nos interesa obtener el símbolo y el nombre de la empresa.
    # Ojo, queremos importar únicamente los activos que tengan cotización. 
    
    activos_con_datos<-as.data.frame(datos_web[seq(3, dim(datos_web)[1], by=6),1])  
    activos_con_datos<-as.vector(t(activos_con_datos))
    indice_datos<-activos_con_datos!="" & activos_con_datos!="0,00"
    
    activos_a_importar<-as.data.frame(datos_web[seq(1, dim(datos_web)[1], by=6),1])
    activos_a_importar<-as.vector(t(activos_a_importar))
    activos_a_importar<-activos_a_importar[indice_datos]
    
    nombres_empresas<-as.data.frame(datos_web[seq(2, dim(datos_web)[1], by=6),1])
    nombres_empresas<-as.vector(t(nombres_empresas))
    nombres_empresas<-nombres_empresas[indice_datos]
    
    num_activos<-length(activos_a_importar)
    
    
    # Extraemos la divisa en la que cotizan los activos.
    datos_web<- web %>%
      html_nodes("span") %>% 
      html_text() 
    datos_web<-as.data.frame(datos_web)
    
    divisa<-""
    for (linea in 1:dim(datos_web)[1]){
      if (divisa==""){
        # Buscamos la subcadena "Divisa en" dentro del contenido de la web
        posicion<-unlist(str_locate_all(pattern ="Divisa en ", datos_web[linea,1]))
        
        if (length(posicion)>0){
          divisa <- substr(datos_web[linea,1], posicion[2] + 1, posicion[2] + 3)
        }
      }
    }
    
  } else {
    print("El índice no tiene activos descargables")
    # return(NA)
  }  
  
  # Importamos los activos que hemos seleccionado.
  for (activo in activos_a_importar){
    
    intentos<-0
    descarga<-"Sin datos"
    while(descarga=="Sin datos"){
      
      info_activo<- obtener_datos_activo(activo, fecha_inicial, fecha_fin, columna_fechas)
      
      # Comprobamos que nos hemos podido descargar el activo.
      if(sum(colSums(info_activo[,2:dim(info_activo)[2]] != 0))>0){
        descarga<-"OK"
      }
      
      intentos<-intentos+1
      
      if(intentos>3){
        print(c("Tras varios intentos no nos hemos podido descargar",activo,"Dejamos de intentarlo."))
        descarga<-"OK"
      }
      
      if(descarga=="Sin datos"){
        print(c("Error en la descarga del activo", activo, "reintentamos"))
        Sys.sleep(10)
      }
    }
    
    assign(activo,info_activo)
  }
  
  # Homogeneizamos los datos (que todos los DF tengan el mismo número de filas / días y que estén puestos en las mismas líneas)
  for (activo in activos_a_importar){
    
    # Recuperamos la información del activo
    datos<- XXXXXXXXXXXXX

    # Invocamos la función homogeneizar
    datos[,1]<-as.Date(datos[,1])
    datos_homogeneizados<-homogeneizar(XXXXXXXXXX, XXXXXXXXXXX)
               
    # Guardamos el DF homogeneizado en su variable original.
    assign(activo,datos_homogeneizados)
  }
}
