{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejercicio 1 historico de RV de cada activo de muchos indices Yahoo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Obtén el histórico (60 días) de cada activo de varios índices (usa el código del día anterior)\n",
    "- Recomendación: Yahoo Finance . # Tiempo objetivo: 45 minutos\n",
    "- La clave está en qué tenemos que hacer cuando un activo de error en la descarga..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejercicio vamos incluir los siguientes controles de error:\n",
    "\n",
    "      Control 1: En la conexión a la web haremos 3 intentos, y si no lo conseguimos, seguimos\n",
    "      Control 2: En los errores de descarga que habiamos ya esbozado en ejercicios previos, hay que devolver la causa del error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "from rcurl import get_curl\n",
    "from io import BytesIO\n",
    "from time import mktime\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funcion que recupera el los datos en bruto de Yahoo finance, realizando el chequeo del crumb.\n",
    "Ver https://maikros.github.io/yahoo-finance-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_crumbs_and_cookies(stock):\n",
    "    \"\"\"\n",
    "    get crumb and cookies for historical data csv download from yahoo finance  \n",
    "    parameters: stock - short-handle identifier of the company    \n",
    "    returns a tuple of header, crumb and cookie\n",
    "    \"\"\"   \n",
    "    url = 'https://finance.yahoo.com/quote/{}/history'.format(stock)\n",
    "    \n",
    "    with requests.session():\n",
    "        \n",
    "        header = {'Connection': 'keep-alive',\n",
    "                   'Expires': '-1',\n",
    "                   'Upgrade-Insecure-Requests': '1',\n",
    "                   'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; WOW64) \\\n",
    "                   AppleWebKit/537.36 (KHTML, like Gecko) Chrome/54.0.2840.99 Safari/537.36'\n",
    "                   }  \n",
    "        \n",
    "        website = requests.get(url, headers=header)\n",
    "        soup = BeautifulSoup(website.text, 'lxml')\n",
    "        \n",
    "        try:\n",
    "            crumb = re.findall('\"CrumbStore\":{\"crumb\":\"(.+?)\"}', str(soup))\n",
    "            output=(header, crumb[0], website.cookies)\n",
    "            return output\n",
    "        \n",
    "        except:\n",
    "            \n",
    "            print('no lo podemos descargar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establecemos el rango de fechas que queremos importar.\n",
    "Yahoo utiliza formato de fecha poxis - time unix\n",
    "(cantidad de segundos transcurridos desde la medianoche UTC del 1 de enero de 1970, teniendo cada día 86400 segundos)\n",
    "Convertimos la fecha a formato poxis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_unix(date):\n",
    "    \"\"\"\n",
    "    converts date to unix timestamp\n",
    "    parameters: date - in format (yyyy-mm-dd)\n",
    "    returns integer unix timestamp\n",
    "    \"\"\"\n",
    "    datum = datetime.strptime(date, '%Y-%m-%d')\n",
    "    \n",
    "    return int(mktime(datum.timetuple()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv_data(stock, interval='1d', day_begin='20-03-2018', day_end='20-06-2018'):\n",
    "    \"\"\"\n",
    "    queries yahoo finance api to receive historical data in csv file format\n",
    "    \n",
    "    parameters: \n",
    "        stock - short-handle identifier of the company\n",
    "        interval - 1d, 1wk, 1mo - daily, weekly monthly data\n",
    "        day_begin - starting date for the historical data (format: dd-mm-yyyy)\n",
    "        day_end - final date of the data (format: dd-mm-yyyy)\n",
    "    \n",
    "    returns a list of comma seperated value lines\n",
    "    \"\"\"\n",
    "    \n",
    "    error1='404 Not Found: Timestamp data missing.'\n",
    "    \n",
    "    day_begin_unix = convert_to_unix(day_begin)\n",
    "    day_end_unix = convert_to_unix(day_end)\n",
    "       \n",
    "    header, crumb, cookies = _get_crumbs_and_cookies(stock)\n",
    "    \n",
    "    with requests.session():\n",
    "        \n",
    "        url = 'https://query1.finance.yahoo.com/v7/finance/download/' \\\n",
    "              '{stock}?period1={day_begin}&period2={day_end}&interval={interval}&events=history&crumb={crumb}' \\\n",
    "              .format(stock=stock, day_begin=day_begin_unix, day_end=day_end_unix, interval=interval, crumb=crumb)\n",
    "                \n",
    "        website = requests.get(url, headers=header, cookies=cookies)\n",
    "       \n",
    "        return website.text.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prueba_conexion1(max_intentos,error1):\n",
    "    \n",
    "    intentos=1\n",
    "    valor_check=website.text.split('\\n')\n",
    "    \n",
    "    for i in range(max_intentos):\n",
    "        \n",
    "        if intentos==3:\n",
    "            print('no intentamos mas')\n",
    "            break\n",
    "            \n",
    "        if valor_check==error1 & max_intentos<=3:\n",
    "            intentos=intentos+1\n",
    "            Sys.sleep(5)\n",
    "            print('reintentamos',intentos)\n",
    "            website = requests.get(url, headers=header, cookies=cookies)\n",
    "            valor_check=website.text.split('\\n') \n",
    "            \n",
    "        else:\n",
    "            return valor_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prueba_conexion2(max_intentos,error1=''):\n",
    "    \n",
    "    intentos=1\n",
    "    valor_check=website.text.split('\\n')\n",
    "    \n",
    "    for i in range(max_intentos):\n",
    "        \n",
    "        if intentos==3:\n",
    "            print('no intentamos mas')\n",
    "            break\n",
    "            \n",
    "        if valor_check==error1 & max_intentos<=3:\n",
    "            intentos=intentos+1\n",
    "            Sys.sleep(5)\n",
    "            print('reintentamos',intentos)\n",
    "            website = requests.get(url, headers=header, cookies=cookies)\n",
    "            valor_check=website.text.split('\\n')  \n",
    "            \n",
    "        else:\n",
    "            return valor_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def componentes_indice(tickers_de_indices):\n",
    "    \"\"\"esta funcion devuelve los componentes y divisa de cada indice.\n",
    "    como parametro se debe inclur los tickers de Yahoo Finance de los indices\n",
    "    en una tupla\"\"\"\n",
    "\n",
    "    n=0\n",
    "    for i in tickers_de_indices:\n",
    "\n",
    "        Index=i\n",
    "        \n",
    "        #primero se obtiene la divisa\n",
    "        url=\"https://es.finance.yahoo.com/quote/\"+i+\"/components/\"\n",
    "        soup  = requests.get(url)\n",
    "        soup  = BeautifulSoup(soup.content, 'html.parser')       \n",
    "        name_box = soup.find('span', attrs={'data-reactid': '4'})\n",
    "        \n",
    "        try:\n",
    "            name = name_box.text.strip()\n",
    "            divisa=name[len(name)-3:len(name)]\n",
    "            print(i,divisa)\n",
    "            \n",
    "            # Reconstruimos la tabla. Tiene 6 columnas (símbolo, nombre de la empresa, último precio, cambio, cambio % y volumen.)\n",
    "            # Nos interesa obtener el símbolo y el nombre de la empresa.\n",
    "            # Ojo, queremos importar únicamente los activos que tengan cotización. \n",
    "            \n",
    "            soup  = requests.get(url)\n",
    "            soup  = BeautifulSoup(soup.content, 'html.parser')\n",
    "           \n",
    "            name_box = soup.find_all('tr')\n",
    "            name_boxccc=name_box[1]\n",
    "            name_boxccc = name_boxccc.get_text(strip=True)\n",
    "            lista_activo2=[]\n",
    "            lista_indice=[]\n",
    "            lista_divisa=[]\n",
    "            lista_num_errores=[]\n",
    "            \n",
    "            lista_resto=[]\n",
    "\n",
    "            for i in range(1,len(name_box)-1):\n",
    "                \n",
    "                try:\n",
    "                    lista_indice.append(Index)\n",
    "                    name_boxccc=name_box[i]\n",
    "                    name_boxccc = name_boxccc.get_text(strip=True)\n",
    "                    name_boxccc=name_boxccc.split(sep='.')\n",
    "                    \n",
    "                    if name_boxccc[0]=='656690656690': #este caso es un activo  que me rompe la descarga del índice brasileno (mejorar)\n",
    "                        \n",
    "                        lista_activo2.append(name_boxccc[0])\n",
    "                        lista_resto.append(name_boxccc)\n",
    "                        lista_divisa.append(divisa)\n",
    "                        \n",
    "                    else:\n",
    "                        lista_activo2.append(name_boxccc[0]+'.'+name_boxccc[1][0:2])                        \n",
    "                        lista_resto.append(name_boxccc)\n",
    "                        lista_divisa.append(divisa)\n",
    "\n",
    "                except:\n",
    "                    lista_num_errores.append(i)\n",
    "\n",
    "            if len(lista_activo2)==len(lista_divisa):\n",
    "\n",
    "                df=pd.DataFrame ({'indice':lista_indice,\n",
    "                                'activo':lista_activo2,\n",
    "                                'divisa':lista_divisa,\n",
    "                                'resto':lista_resto})\n",
    "                \n",
    "                df['posicion']=np.where(df['resto'].astype(str).str.contains('%', regex=False)==True,1,0)\n",
    "\n",
    "                df=df[df['posicion']==1]\n",
    "                df=df.drop(['resto','posicion'],1)\n",
    "\n",
    "                if n==0:\n",
    "                    dfacum=df\n",
    "                else:\n",
    "                    dfacum=pd.concat([dfacum, df], axis=0,sort=True)\n",
    "                    dfacum.reset_index(drop=True)\n",
    "                    \n",
    "                n=n+1\n",
    "\n",
    "            else:\n",
    "                print('El activo '+str(i)+'no se ha podido incorporar por inconsistencias en los datos importados')\n",
    "\n",
    "        except:\n",
    "            print('Para la referencia '+str(i)+' no se ha podido descargar la informacion')\n",
    "    \n",
    "    return dfacum    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_dates(x,ventana):\n",
    "    \"\"\"setup inicial de fechas,\n",
    "    esta funcion devuelve la fecha de inicio\n",
    "    y fin en string y formato YYYY-MM-DD\n",
    "    Parametros:\n",
    "    x=start o end\n",
    "    ventana: entero referido al numero de dias del periodo\"\"\"\n",
    "    \n",
    "    hoy=datetime.now()\n",
    "    \n",
    "    if x=='end':\n",
    "        fecha_fin = str(hoy.now())\n",
    "        fecha_fin = fecha_fin[0:10]\n",
    "        return (fecha_fin)\n",
    "    \n",
    "    if x=='start':\n",
    "        fecha_inicial=hoy-timedelta(ventana)\n",
    "        fecha_inicial = str(fecha_inicial)\n",
    "        fecha_inicial = fecha_inicial[0:10]\n",
    "        return (fecha_inicial)\n",
    "    \n",
    "    else:\n",
    "        print('inputs incorrectos. Ver docstring d ela funcion')       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def historic_prices_series(stock_series,interval,fecha_inicial,fecha_fin):\n",
    "    \n",
    "    n=0\n",
    "    x=0 \n",
    "    \n",
    "    for benchmark in stock_series:\n",
    "        \n",
    "        print(\"descargando \"+benchmark+' del indice')\n",
    "        \n",
    "        try:\n",
    "            DF=load_csv_data(benchmark, interval=interval, day_begin=fecha_inicial, day_end=fecha_fin)\n",
    "            DF=pd.DataFrame(DF)\n",
    "            DF = DF.iloc[:,0].str.split(\",\", n = 7, expand = True)\n",
    "            DF.columns=DF.iloc[0,:]\n",
    "            DF=DF.iloc[1:DF.shape[0],:]\n",
    "            x=DF.shape[1]  \n",
    "            \n",
    "            if x<2:\n",
    "                 print(\"No nos hemos podido descargar el activo\", benchmark)\n",
    "                    \n",
    "            else:\n",
    "                DF['stock']=str(benchmark)\n",
    "                DF=DF.dropna()\n",
    "            \n",
    "                if n==0:\n",
    "                    dfacum=DF\n",
    "                else:\n",
    "                    dfacum=agrega_dataframes(DF,dfacum)    \n",
    "                n=n+1\n",
    "                \n",
    "        except KeyError as e:\n",
    "            \n",
    "            print(\"No nos hemos podido descargar el indice\")\n",
    "            print(f'key error: {e}')\n",
    "        \n",
    "    return dfacum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agrega_dataframes(df,dfacum):\n",
    "    \"\"\"codigo que permite ir concatenando\n",
    "    dataframes con estructura similar\n",
    "    df:daframe a agregar\n",
    "    dfacum: dataframe en donde se agregara\"\"\"\n",
    "    \n",
    "    dfacum=pd.concat([dfacum, df], axis=0,sort=True)\n",
    "    dfacum.reset_index(drop=True)\n",
    "    return dfacum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ejecucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers_de_indices=(\"%5EBFX\",\"%5EBVSP\",\"%5EFCHI\", \"%5EGDAXI\", \"%5EHSI\", \"%5EIBEX\") \n",
    "                    #\"%5EMXX\", \"%5EJKSE\", \"%5EMERV\", \"%5EOMXSPI\", \"%5EOSEAX\", \"%5ESSMI\", \"%5ESTI\")\n",
    "\n",
    "ventana=60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%5EBFX EUR\n",
      "%5EBVSP BRL\n",
      "%5EFCHI EUR\n",
      "%5EGDAXI EUR\n",
      "%5EHSI HKD\n",
      "%5EIBEX EUR\n",
      "%5EMXX MXN\n",
      "Para la referencia %5EJKSE no se ha podido descargar la informacion\n",
      "%5EMERV  en\n",
      "%5EOMXSPI SEK\n",
      "%5EOSEAX NOK\n",
      "%5ESSMI CHF\n",
      "%5ESTI SGD\n"
     ]
    }
   ],
   "source": [
    "dfacum = componentes_indice(tickers_de_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activo</th>\n",
       "      <th>divisa</th>\n",
       "      <th>indice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UCB.BR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>%5EBFX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>KBC.BR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>%5EBFX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>COFB.BR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>%5EBFX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ONTEX.BR</td>\n",
       "      <td>EUR</td>\n",
       "      <td>%5EBFX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PCAR4.SA</td>\n",
       "      <td>BRL</td>\n",
       "      <td>%5EBVSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ECOR3.SA</td>\n",
       "      <td>BRL</td>\n",
       "      <td>%5EBVSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENBR3.SA</td>\n",
       "      <td>BRL</td>\n",
       "      <td>%5EBVSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JBSS3.SA</td>\n",
       "      <td>BRL</td>\n",
       "      <td>%5EBVSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RADL3.SA</td>\n",
       "      <td>BRL</td>\n",
       "      <td>%5EBVSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>VIVT4.SA</td>\n",
       "      <td>BRL</td>\n",
       "      <td>%5EBVSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BRKM5.SA</td>\n",
       "      <td>BRL</td>\n",
       "      <td>%5EBVSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>KLBN11.SA</td>\n",
       "      <td>BRL</td>\n",
       "      <td>%5EBVSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PETR4.SA</td>\n",
       "      <td>BRL</td>\n",
       "      <td>%5EBVSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LAME4.SA</td>\n",
       "      <td>BRL</td>\n",
       "      <td>%5EBVSP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>OIBR4.SA</td>\n",
       "      <td>BRL</td>\n",
       "      <td>%5EBVSP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       activo divisa   indice\n",
       "3      UCB.BR    EUR   %5EBFX\n",
       "9      KBC.BR    EUR   %5EBFX\n",
       "13    COFB.BR    EUR   %5EBFX\n",
       "14   ONTEX.BR    EUR   %5EBFX\n",
       "0    PCAR4.SA    BRL  %5EBVSP\n",
       "1    ECOR3.SA    BRL  %5EBVSP\n",
       "2    ENBR3.SA    BRL  %5EBVSP\n",
       "3    JBSS3.SA    BRL  %5EBVSP\n",
       "4    RADL3.SA    BRL  %5EBVSP\n",
       "8    VIVT4.SA    BRL  %5EBVSP\n",
       "9    BRKM5.SA    BRL  %5EBVSP\n",
       "10  KLBN11.SA    BRL  %5EBVSP\n",
       "11   PETR4.SA    BRL  %5EBVSP\n",
       "12   LAME4.SA    BRL  %5EBVSP\n",
       "13   OIBR4.SA    BRL  %5EBVSP"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfacum.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_series = dfacum['activo']\n",
    "index_series = dfacum['indice']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "la fecha de inicio es 2020-05-01  y la de fin es 2020-06-30\n"
     ]
    }
   ],
   "source": [
    "fecha_fin = set_dates('end',ventana)\n",
    "fecha_inicial = set_dates('start',ventana)\n",
    "\n",
    "print('la fecha de inicio es',fecha_inicial,' y la de fin es',fecha_fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "descargando UCB.BR del indice\n",
      "descargando KBC.BR del indice\n",
      "descargando COFB.BR del indice\n",
      "descargando ONTEX.BR del indice\n",
      "descargando PCAR4.SA del indice\n",
      "no lo podemos descargar\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-570a8250abff>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfacum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhistoric_prices_series\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock_series\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'1d'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfecha_inicial\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfecha_fin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-15-b33b1c42dfa4>\u001b[0m in \u001b[0;36mhistoric_prices_series\u001b[1;34m(stock_series, interval, fecha_inicial, fecha_fin)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m             \u001b[0mDF\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mload_csv_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbenchmark\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday_begin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfecha_inicial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mday_end\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfecha_fin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m             \u001b[0mDF\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m             \u001b[0mDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\",\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-eb335601ce67>\u001b[0m in \u001b[0;36mload_csv_data\u001b[1;34m(stock, interval, day_begin, day_end)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[0mday_end_unix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconvert_to_unix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mday_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mheader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrumb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcookies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_crumbs_and_cookies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstock\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "dfacum = historic_prices_series(stock_series,'1d',fecha_inicial,fecha_fin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dejamos el Data Frame preparado para el siguiente ejercicio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-9af060cd6ff3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfacum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdfacum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdfacum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdfacum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'stock'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Adj Close'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'High'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Low'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Open'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Volume'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdfacum\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\gmelendez\\python-venv\\venv-ml\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5065\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5066\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5067\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5068\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5069\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Date'"
     ]
    }
   ],
   "source": [
    "dfacum.index=dfacum.Date\n",
    "dfacum=dfacum.loc[:,['stock','Adj Close','High','Low','Open','Volume']]\n",
    "\n",
    "dfacum.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
